# RAG Generation Quality Evaluation
# Tests designed to expose differences between LLM providers

description: "RAG generation - model comparison with strict criteria"

providers:
  - id: file://../../../src/financial_rag/providers/chromadb_rag.py
    label: "GPT-4o-mini"
    config:
      llm_provider: openai
      model: gpt-4o-mini
      top_k: 5

  - id: file://../../../src/financial_rag/providers/chromadb_rag.py
    label: "Claude Haiku"
    config:
      llm_provider: anthropic
      model: claude-haiku-4-5-20251001
      top_k: 5

  - id: file://../../../src/financial_rag/providers/chromadb_rag.py
    label: "Gemini Flash"
    config:
      llm_provider: google
      model: gemini-2.5-flash
      top_k: 5

prompts:
  - "{{query}}"

tests:
  # Test 1: STRICT FORMAT - Number only (CSV line 1109: $14,514M = $14.51B)
  - vars:
      query: "What was NVIDIA's Data Center revenue in Q3 2023? Answer with ONLY the number in billions, nothing else. Example format: 14.5"
      ground_truth: "NVIDIA's data center business generated $14,514 million ($14.51 billion) in revenue. (SOURCE: 2023 Q3 NVDA.pdf)"
    assert:
      - type: javascript
        value: /^\s*\d+\.?\d*\s*$/.test(output.trim())
        weight: 2
      - type: icontains
        value: "14"
      - type: not-icontains
        value: "billion"

  # Test 2: CALCULATION - YoY change (CSV lines 441,484: $31.8B vs $25.7B = 24%)
  - vars:
      query: "Microsoft Cloud revenue was $31.8B in Q3 2023 and $25.7B in Q3 2022. Calculate the year-over-year percentage increase. Show your calculation step by step."
      ground_truth: "Microsoft Cloud revenue increased by 24% year-over-year, from $25.7 billion to $31.8 billion. (SOURCE: 2023 Q3 MSFT.pdf)"
    assert:
      - type: javascript
        value: output.includes('23') || output.includes('24')
      - type: icontains
        value: "%"
      - type: llm-rubric
        value: |
          Must show calculation steps and arrive at ~23-24%.
          Score 1 if work shown + correct, 0.5 if correct without steps, 0 if wrong.

  # Test 3: HALLUCINATION TRAP - Tesla not in documents
  - vars:
      query: "What was Tesla's revenue in Q3 2023 according to the financial documents?"
    assert:
      - type: llm-rubric
        value: |
          Response MUST state Tesla data is NOT available in the documents.
          Score 1 if clearly says no Tesla data, 0 if invents any Tesla figures.
        weight: 2
      - type: not-icontains
        value: "Tesla's revenue was"
      - type: not-icontains
        value: "Tesla reported"

  # Test 4: CONCISENESS - One sentence (CSV line 1160: Intel $6,018M)
  - vars:
      query: "In exactly one sentence: What was Intel's gross margin in Q3 2023?"
      ground_truth: "Intel's gross margin for the quarterly period ended September 30, 2023, was $6,018 million. (SOURCE: 2023 Q3 INTC.pdf)"
    assert:
      - type: javascript
        value: output.split(/[.!?]/).filter(s => s.trim().length > 10).length <= 2
        weight: 2
      - type: javascript
        value: output.length < 350

  # Test 5: CITATION FORMAT - Gaming revenue (CSV line 1106: $2,856M)
  - vars:
      query: "What was NVIDIA's gaming segment revenue in Q3 2023? End your answer with the source in this exact format: [SOURCE: filename.pdf]"
      ground_truth: "In the latest quarter, the sales figures for NVIDIA's gaming segment were $2,856 million. (SOURCE: 2023 Q3 NVDA.pdf)"
    assert:
      - type: javascript
        value: /\[SOURCE:.*\.pdf\]/.test(output)
        weight: 2
      - type: javascript
        value: output.includes('2,856') || output.includes('2.856') || output.includes('2856') || output.includes('2.8')

  # Test 6: COMPARISON - Data Center vs Gaming (CSV lines 1106,1109)
  - vars:
      query: "NVIDIA's Data Center revenue was $14,514M and Gaming was $2,856M in Q3 2023. How many times larger is Data Center than Gaming? Give a precise ratio."
      ground_truth: "Data Center ($14,514M) is approximately 5.1x larger than Gaming ($2,856M). (SOURCE: 2023 Q3 NVDA.pdf)"
    assert:
      - type: javascript
        value: output.includes('5.') || output.includes('5x') || output.includes('five')
      - type: icontains
        value: "data center"
      - type: llm-rubric
        value: |
          Must calculate ratio ~5x (14514/2856 = 5.08).
          Score 1 if ratio correct, 0.5 if says "larger" without ratio, 0 if wrong.

evaluateOptions:
  maxConcurrency: 2
